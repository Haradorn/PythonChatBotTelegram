{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skillbox Char Bot Day 1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6Nkeq4J2YcQ"
      },
      "source": [
        "import nltk\r\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oB9QTH2truj"
      },
      "source": [
        "# BOT_CONFIG = {\r\n",
        "#     \"intents\": { # Намерения\r\n",
        "#         \"hello\": { # Намерение поздароваться\r\n",
        "#             \"examples\": [\"Привет\", \"Добрый день\", \"Шалом\", \"Здравствуйте\"],\r\n",
        "#             \"responses\": [\"Привет, человек\", \"Доброго времени суток\"]\r\n",
        "#         },\r\n",
        "#         \"bye\": {\r\n",
        "#             \"examples\": [\"Пока\", \"Досвидос\", \"Прощай\"],\r\n",
        "#             \"responses\": [\"Счастливо\", \"До свидания\", \"Если что, возвращайтесь\"],\r\n",
        "#         },\r\n",
        "#         \"howdoyoudo\": {\r\n",
        "#             \"examples\": [\"Как дела\", \"Что делаешь\", \"Какие дела\"],\r\n",
        "#             \"responses\": [\"Маюсь фигней\", \"Отвечаю на дурацкие вопросы\", \"Веду вебинары\"],\r\n",
        "#         },\r\n",
        "#     },\r\n",
        "#     \"failure_phrases\": [\r\n",
        "#         \"Я ничо не понил\",\r\n",
        "#         \"Что-то непонятно\",\r\n",
        "#         \"Я всего лишь бот, сформулируйте попроще\"\r\n",
        "#     ]\r\n",
        "# }\r\n",
        "\r\n",
        "def filter(text):\r\n",
        "  text = text.lower()\r\n",
        "  text = [c for c in text if c in 'абвгджзеёийклмнопрстуфхцчшщьыъэюя -']\r\n",
        "  return ''.join(text)\r\n",
        "\r\n",
        "def match(text, example): # \"прощяй!\" === \"Прощай\" ??\r\n",
        "  text = filter(text)\r\n",
        "  #example = example\r\n",
        "  \r\n",
        "  distance = nltk.edit_distance(text, example) / len(example)\r\n",
        "  if distance < 0.4:\r\n",
        "    return True # Текст совпадает\r\n",
        "  else:\r\n",
        "    return False # Текст НЕ совпадает"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pPV9vAFwDPv"
      },
      "source": [
        "def get_intent(text): \r\n",
        "  for intent, data in BOT_CONFIG['intents'].items():\r\n",
        "    for example in data['examples']:\r\n",
        "      if match(text, example):\r\n",
        "        return intent"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMzIna_6xhVl"
      },
      "source": [
        "def get_answer_by_intent(intent):\r\n",
        "  phrases = BOT_CONFIG['intents'][intent]['responses']\r\n",
        "  return random.choice(phrases)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BNZP8PE3rx7"
      },
      "source": [
        "def bot(text):\r\n",
        "  intent = get_intent(text)\r\n",
        "\r\n",
        "  if not intent:\r\n",
        "    intent = get_intent_predictive_model(text)\r\n",
        "\r\n",
        "  print(\"Intent = \", intent)\r\n",
        "\r\n",
        "  if intent:\r\n",
        "    return get_answer_by_intent(intent)\r\n",
        "\r\n",
        "  failure_phrases = BOT_CONFIG['failure_phrases']\r\n",
        "  return random.choice(failure_phrases)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEOk2aGY6YSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5446d0c-7b0e-495e-88a1-a15508a541af"
      },
      "source": [
        "question = ''\r\n",
        "while question not in ['выход', 'отстань']:\r\n",
        "  question = input()\r\n",
        "  answer = bot(question)\r\n",
        "  print(answer)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "выход\n",
            "Intent =  bye\n",
            "Если что, я тут. Возвращайтесь!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nsgt64E7Gw0"
      },
      "source": [
        "import json"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t6sbKS6qC88"
      },
      "source": [
        "config_file = open(\"/content/big_bot_config.json\", \"r\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtDRYhOhqR4d"
      },
      "source": [
        "BOT_CONFIG = json.load(config_file)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thr61i-Fqc71",
        "outputId": "2cc0a6a5-7a48-41b4-ef32-16c773e08ae6"
      },
      "source": [
        "len(BOT_CONFIG[\"intents\"])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "439"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21MehEP4roMi"
      },
      "source": [
        "Задача: классифицировать намерения пользователя, т.е. на основе фразы спрогнозировать \"интент\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOQ5YA15sjg6"
      },
      "source": [
        "Фразы => Намерение\r\n",
        "Х(вход) => Y(выходные)\r\n",
        "1. Модель (алгоритм) М.О. = Классификатор (Classifier)\r\n",
        "2. Преобразование данных (Векторайзер) Vectorizer\r\n",
        "Задача Vectorizer это из текста сделать числа (какие-то и как-то)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiS3KwNZrytm"
      },
      "source": [
        "X_examples = []\r\n",
        "y = []\r\n",
        "for intent, data in BOT_CONFIG['intents'].items():\r\n",
        "  for example in data['examples']:\r\n",
        "    X_examples.append(example)\r\n",
        "    y.append(intent)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGw1KKFFv0OK"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6e6AphDwPbM",
        "outputId": "27428920-3225-44cd-bfe2-c33832860de0"
      },
      "source": [
        "count_vecrorizer = CountVectorizer()\r\n",
        "count_vecrorizer.fit(X_examples)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyPZPtjA1HU7"
      },
      "source": [
        "# list(count_vecrorizer.transform(['ты там че делаешь то']).nonzero()[1])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75JjanL01tiF"
      },
      "source": [
        "X = count_vecrorizer.transform(X_examples)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10dfVAbC17Kn"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gurNAhtm1-6L",
        "outputId": "4d5e38e6-bb29-4032-8ed5-c6445cf640ba"
      },
      "source": [
        "log_reg = LogisticRegression() #Настройки\r\n",
        "log_reg.fit(X, y)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xu6JSPO2Gcw",
        "outputId": "e689a1a3-346c-4077-a934-03b0ebe08fb7"
      },
      "source": [
        "log_reg.predict(count_vecrorizer.transform(['ну расскажи анекдот']))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['jokes'], dtype='<U29')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BqEMQCV3B9S",
        "outputId": "9cb4ee03-c0ee-4624-e5b9-d0503e29d029"
      },
      "source": [
        "log_reg.score(X, y)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38840772818121255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKhFPCRN3GpI"
      },
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdrjlH_93f6A"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "tfidf_vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2,4))\r\n",
        "X = tfidf_vectorizer.fit_transform(X_examples)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEF9jlRb5ged"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "    X, y, test_size = 0.33\r\n",
        ")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIIoSgc254jN",
        "outputId": "253c75ad-a186-41ad-a1a7-f729db324e72"
      },
      "source": [
        "lin_svc = LinearSVC()\r\n",
        "lin_svc.fit(X_train, y_train)\r\n",
        "print(\"Train\", lin_svc.score(X_train, y_train))\r\n",
        "print(\"Test\", lin_svc.score(X_test, y_test))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train 0.8632521133764296\n",
            "Test 0.3249243188698285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI2S2v546IiF"
      },
      "source": [
        "def get_intent_predictive_model(text):\r\n",
        "  return lin_svc.predict(tfidf_vectorizer.transform([text]))[0]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OfkjwijEHGU"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz3fQ4RLEJJR"
      },
      "source": [
        "pickle.dump(lin_svc, open(\"lin_svc.model\", \"wb\"))\r\n",
        "pickle.dump(tfidf_vectorizer, open(\"tfidf_vectorizer.model\", \"wb\"))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySzU0LAM2qIL",
        "outputId": "437b8437-ee21-4eea-9de1-c091fe412a9c"
      },
      "source": [
        "! pip install python-telegram-bot --upgrade"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: python-telegram-bot in /usr/local/lib/python3.6/dist-packages (13.1)\n",
            "Requirement already satisfied, skipping upgrade: cryptography in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (3.3.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2018.6 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: APScheduler==3.6.3 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (3.6.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.14.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (51.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tzlocal>=1.2 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography->python-telegram-bot) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anR0vVKz2xoy"
      },
      "source": [
        "from telegram import Update\r\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL0gQaDn3Mpu"
      },
      "source": [
        "def start(update: Update, context: CallbackContext) -> None:\r\n",
        "    \"\"\"Send a message when the command /start is issued.\"\"\"\r\n",
        "    update.message.reply_text('Hi!')\r\n",
        "\r\n",
        "\r\n",
        "def help_command(update: Update, context: CallbackContext) -> None:\r\n",
        "    \"\"\"Send a message when the command /help is issued.\"\"\"\r\n",
        "    update.message.reply_text('I\\'m very intelligent AI creature!')\r\n",
        "\r\n",
        "\r\n",
        "def echo(update: Update, context: CallbackContext) -> None:\r\n",
        "    \"\"\"Echo the user message.\"\"\"\r\n",
        "    answer = bot(update.message.text)\r\n",
        "    update.message.reply_text(answer)\r\n",
        "\r\n",
        "\r\n",
        "def main():\r\n",
        "    \"\"\"Start the bot.\"\"\"\r\n",
        "    # Create the Updater and pass it your bot's token.\r\n",
        "    # Make sure to set use_context=True to use the new context based callbacks\r\n",
        "    # Post version 12 this will no longer be necessary\r\n",
        "    updater = Updater(\"1474068577:AAEOuQoOn5p5bTPHeN3NMu74qT7MVmyhq-w\", use_context=True)\r\n",
        "\r\n",
        "    # Get the dispatcher to register handlers\r\n",
        "    dispatcher = updater.dispatcher\r\n",
        "\r\n",
        "    # on different commands - answer in Telegram\r\n",
        "    dispatcher.add_handler(CommandHandler(\"start\", start))\r\n",
        "    dispatcher.add_handler(CommandHandler(\"help\", help_command))\r\n",
        "\r\n",
        "    # on noncommand i.e message - echo the message on Telegram\r\n",
        "    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, echo))\r\n",
        "\r\n",
        "    # Start the Bot\r\n",
        "    updater.start_polling()\r\n",
        "\r\n",
        "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\r\n",
        "    # SIGTERM or SIGABRT. This should be used most of the time, since\r\n",
        "    # start_polling() is non-blocking and will stop the bot gracefully.\r\n",
        "    updater.idle()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpMOtF7f4Z0r",
        "outputId": "1bc5c660-afb0-4281-8dfe-22407eca777e"
      },
      "source": [
        "main()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intent =  hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRlhlTUD8t73"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}